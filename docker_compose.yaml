services:
    python-service:
        profiles: ["python"]
        build:
            dockerfile: ./Dockerfile.python
            context: .
        container_name: thinking-python
        restart: no
        volumes:
            - ./artifacts/log:/app/log
            - ./artifacts/cache:/app/cache
            - ./artifacts/experiments:/app/experiments
            - ./artifacts/pip_modules:/app/pip_modules
            - ./quest_interface:/app/quest_interface
            - ./implementations:/app/implementations
            - ./prompt_directory:/app/prompt_directory
            - ./utilities:/app/utilities
            - ./tasks:/app/tasks
        environment:
            - ERROR_LOG=/app/log/error.log
            - LOG_LEVEL=info
            - PYTHONUNBUFFERED=TRUE
            - TF_CPP_MIN_LOG_LEVEL=0
        env_file:
            - ./secrets.env
        ports:
            - "127.0.0.1:43690:43690"
        networks:
            - app_network
    torch-cpu-service:
        profiles: ["torch-cpu"]
        build:
            dockerfile: ./Dockerfile.torch-cpu
            context: .
        container_name: thinking-torch-cpu
        restart: no
        volumes:
            - ./artifacts/log:/app/log
            - ./artifacts/cache:/app/cache
            - ./artifacts/experiments:/app/experiments
            - ./artifacts/pip_modules:/app/pip_modules
            - ./quest_interface:/app/quest_interface
            - ./implementations:/app/implementations
            - ./prompt_directory:/app/prompt_directory
            - ./utilities:/app/utilities
            - ./tasks:/app/tasks
        environment:
            - ERROR_LOG=/app/log/error.log
            - LOG_LEVEL=info
            - PYTHONUNBUFFERED=TRUE
            - TF_CPP_MIN_LOG_LEVEL=0
        env_file:
            - ./secrets.env
        ports:
            - "127.0.0.1:43690:43690"
        networks:
            - app_network
    torch-cuda-service:
        profiles: ["torch-cuda"]
        build:
            dockerfile: ./Dockerfile.torch-cuda
            context: .
        container_name: thinking-torch-cuda
        restart: no
        volumes:
            - ./artifacts/log:/app/log
            - ./artifacts/cache:/app/cache
            - ./artifacts/experiments:/app/experiments
            - ./artifacts/pip_modules:/app/pip_modules
            - ./quest_interface:/app/quest_interface
            - ./implementations:/app/implementations
            - ./prompt_directory:/app/prompt_directory
            - ./utilities:/app/utilities
            - ./tasks:/app/tasks
        environment:
            - ERROR_LOG=/app/log/error.log
            - LOG_LEVEL=info
            - PYTHONUNBUFFERED=TRUE
            - TF_CPP_MIN_LOG_LEVEL=0
        env_file:
            - ./secrets.env
        ports:
            - "127.0.0.1:43690:43690"
        networks:
            - app_network
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: 1
                          capabilities: [gpu]
    torch-rocm-service:
        profiles: ["torch-rocm"]
        build:
            dockerfile: ./Dockerfile.torch-rocm
            context: .
        container_name: thinking-torch-rocm
        restart: no
        volumes:
            - ./artifacts/log:/app/log
            - ./artifacts/cache:/app/cache
            - ./artifacts/experiments:/app/experiments
            - ./artifacts/pip_modules:/app/pip_modules
            - ./quest_interface:/app/quest_interface
            - ./implementations:/app/implementations
            - ./prompt_directory:/app/prompt_directory
            - ./utilities:/app/utilities
            - ./tasks:/app/tasks
        environment:
            - ERROR_LOG=/app/log/error.log
            - LOG_LEVEL=info
            - PYTHONUNBUFFERED=TRUE
            - TF_CPP_MIN_LOG_LEVEL=0
        env_file:
            - ./secrets.env
        ports:
            - "127.0.0.1:43690:43690"
        networks:
            - app_network
        devices:
            - /dev/kfd
            - /dev/dri
        security_opt:
            - seccomp:unconfined
    torch-rocm-gptq-service:
        profiles: ["torch-rocm"]
        build:
            dockerfile: ./Dockerfile.torch-rocm-gptq
            context: .
        container_name: thinking-torch-rocm-gptq
        restart: no
        volumes:
            - ./artifacts/log:/app/log
            - ./artifacts/cache:/app/cache
            - ./artifacts/experiments:/app/experiments
            - ./artifacts/pip_modules:/app/pip_modules
            - ./quest_interface:/app/quest_interface
            - ./implementations:/app/implementations
            - ./prompt_directory:/app/prompt_directory
            - ./utilities:/app/utilities
            - ./tasks:/app/tasks
        environment:
            - ERROR_LOG=/app/log/error.log
            - LOG_LEVEL=info
            - PYTHONUNBUFFERED=TRUE
            - TF_CPP_MIN_LOG_LEVEL=0
        env_file:
            - ./secrets.env
        ports:
            - "127.0.0.1:43690:43690"
        networks:
            - app_network
        devices:
            - /dev/kfd
            - /dev/dri
        security_opt:
            - seccomp:unconfined
networks:
    app_network:
        driver: bridge
